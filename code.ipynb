{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6833f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated ETL Pipeline & Dashboard Deployment Script\n",
    "# This script automates the entire sales data pipeline process\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import schedule\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom ETL class\n",
    "from sales_etl_pipeline import SalesDataETL\n",
    "\n",
    "class SalesAutomationManager:\n",
    "    \"\"\"\n",
    "    Comprehensive automation manager for sales data pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_file='config.json'):\n",
    "        self.config = self.load_config(config_file)\n",
    "        self.setup_logging()\n",
    "        self.etl = SalesDataETL(self.config.get('database_path', 'sales_data.db'))\n",
    "        \n",
    "    def load_config(self, config_file):\n",
    "        \"\"\"Load configuration from JSON file\"\"\"\n",
    "        default_config = {\n",
    "            \"database_path\": \"sales_data.db\",\n",
    "            \"backup_path\": \"backups/\",\n",
    "            \"log_path\": \"logs/\",\n",
    "            \"email_alerts\": {\n",
    "                \"enabled\": False,\n",
    "                \"smtp_server\": \"smtp.gmail.com\",\n",
    "                \"smtp_port\": 587,\n",
    "                \"sender_email\": \"\",\n",
    "                \"sender_password\": \"\",\n",
    "                \"recipients\": []\n",
    "            },\n",
    "            \"data_sources\": {\n",
    "                \"crm_api_url\": \"\",\n",
    "                \"erp_api_url\": \"\",\n",
    "                \"pos_api_url\": \"\"\n",
    "            },\n",
    "            \"quality_thresholds\": {\n",
    "                \"min_daily_transactions\": 100,\n",
    "                \"max_transaction_amount\": 10000,\n",
    "                \"data_freshness_hours\": 24\n",
    "            },\n",
    "            \"schedule\": {\n",
    "                \"etl_frequency\": \"hourly\",  # hourly, daily, weekly\n",
    "                \"backup_frequency\": \"daily\",\n",
    "                \"report_frequency\": \"weekly\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(config_file):\n",
    "                with open(config_file, 'r') as f:\n",
    "                    user_config = json.load(f)\n",
    "                    default_config.update(user_config)\n",
    "            else:\n",
    "                # Create default config file\n",
    "                with open(config_file, 'w') as f:\n",
    "                    json.dump(default_config, f, indent=2)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading config: {e}. Using defaults.\")\n",
    "            \n",
    "        return default_config\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Setup comprehensive logging\"\"\"\n",
    "        log_dir = Path(self.config['log_path'])\n",
    "        log_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        log_file = log_dir / f\"sales_automation_{datetime.now().strftime('%Y%m%d')}.log\"\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger('SalesAutomation')\n",
    "    \n",
    "    def create_backup(self):\n",
    "        \"\"\"Create database backup\"\"\"\n",
    "        try:\n",
    "            backup_dir = Path(self.config['backup_path'])\n",
    "            backup_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            backup_file = backup_dir / f\"sales_backup_{timestamp}.db\"\n",
    "            \n",
    "            # Copy database file\n",
    "            import shutil\n",
    "            shutil.copy2(self.config['database_path'], backup_file)\n",
    "            \n",
    "            self.logger.info(f\"Database backup created: {backup_file}\")\n",
    "            \n",
    "            # Cleanup old backups (keep last 7 days)\n",
    "            cutoff_date = datetime.now() - timedelta(days=7)\n",
    "            for backup in backup_dir.glob(\"sales_backup_*.db\"):\n",
    "                if backup.stat().st_mtime < cutoff_date.timestamp():\n",
    "                    backup.unlink()\n",
    "                    self.logger.info(f\"Removed old backup: {backup}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Backup failed: {str(e)}\")\n",
    "            self.send_alert(\"Backup Failed\", f\"Database backup failed: {str(e)}\")\n",
    "    \n",
    "    def validate_data_quality(self):\n",
    "        \"\"\"Perform data quality checks\"\"\"\n",
    "        quality_issues = []\n",
    "        \n",
    "        try:\n",
    "            with sqlite3.connect(self.config['database_path']) as conn:\n",
    "                # Check transaction count\n",
    "                today = datetime.now().strftime('%Y-%m-%d')\n",
    "                result = pd.read_sql(\n",
    "                    \"SELECT COUNT(*) as count FROM sales_transactions WHERE DATE(transaction_date) = ?\",\n",
    "                    conn, params=[today]\n",
    "                )\n",
    "                \n",
    "                daily_count = result.iloc[0]['count']\n",
    "                min_threshold = self.config['quality_thresholds']['min_daily_transactions']\n",
    "                \n",
    "                if daily_count < min_threshold:\n",
    "                    issue = f\"Low transaction count today: {daily_count} (expected: >{min_threshold})\"\n",
    "                    quality_issues.append(issue)\n",
    "                    self.logger.warning(issue)\n",
    "                \n",
    "                # Check for anomalous transaction amounts\n",
    "                result = pd.read_sql(\n",
    "                    \"SELECT MAX(total_amount) as max_amount FROM sales_transactions WHERE DATE(transaction_date) = ?\",\n",
    "                    conn, params=[today]\n",
    "                )\n",
    "                \n",
    "                max_amount = result.iloc[0]['max_amount'] or 0\n",
    "                max_threshold = self.config['quality_thresholds']['max_transaction_amount']\n",
    "                \n",
    "                if max_amount > max_threshold:\n",
    "                    issue = f\"Unusually high transaction detected: ${max_amount:,.2f}\"\n",
    "                    quality_issues.append(issue)\n",
    "                    self.logger.warning(issue)\n",
    "                \n",
    "                # Check data freshness\n",
    "                result = pd.read_sql(\n",
    "                    \"SELECT MAX(transaction_date) as latest_date FROM sales_transactions\",\n",
    "                    conn\n",
    "                )\n",
    "                \n",
    "                if result.iloc[0]['latest_date']:\n",
    "                    latest_date = datetime.strptime(result.iloc[0]['latest_date'], '%Y-%m-%d')\n",
    "                    hours_old = (datetime.now() - latest_date).total_seconds() / 3600\n",
    "                    freshness_threshold = self.config['quality_thresholds']['data_freshness_hours']\n",
    "                    \n",
    "                    if hours_old > freshness_threshold:\n",
    "                        issue = f\"Data is stale: {hours_old:.1f} hours old (threshold: {freshness_threshold}h)\"\n",
    "                        quality_issues.append(issue)\n",
    "                        self.logger.warning(issue)\n",
    "                \n",
    "        except Exception as e:\n",
    "            issue = f\"Data quality check failed: {str(e)}\"\n",
    "            quality_issues.append(issue)\n",
    "            self.logger.error(issue)\n",
    "        \n",
    "        return quality_issues\n",
    "    \n",
    "    def generate_performance_report(self):\n",
    "        \"\"\"Generate automated performance report\"\"\"\n",
    "        try:\n",
    "            report_data = self.etl.generate_kpi_report()\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            # Create HTML report\n",
    "            html_report = f\"\"\"\n",
    "            <html>\n",
    "            <head><title>Sales Performance Report - {datetime.now().strftime('%Y-%m-%d')}</title></head>\n",
    "            <body style=\"font-family: Arial, sans-serif; margin: 40px;\">\n",
    "                <h1>üìä Sales Performance Report</h1>\n",
    "                <p><strong>Generated:</strong> {timestamp}</p>\n",
    "                \n",
    "                <h2>üìà Revenue Trends</h2>\n",
    "                {report_data['revenue_trends'].to_html(index=False, table_id='revenue-table')}\n",
    "                \n",
    "                <h2>üèÜ Top Products</h2>\n",
    "                {report_data['top_products'].head(10).to_html(index=False, table_id='products-table')}\n",
    "                \n",
    "                <h2>üë• Customer Segments</h2>\n",
    "                {report_data['customer_segments'].to_html(index=False, table_id='segments-table')}\n",
    "                \n",
    "                <style>\n",
    "                    table {{ border"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
